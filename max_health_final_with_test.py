# -*- coding: utf-8 -*-
"""Max health final

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/chandrashekharkeeli/max-health-final.243018ba-568a-4d76-acdc-666d85a9543b.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20260203/auto/storage/goog4_request%26X-Goog-Date%3D20260203T024121Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D96665ff8869bb85ae4c673f3146da791b193b56d2e2ef737fc7ed9788b1e42b73ad63261ab899b017c93cf7744a1ca85c8ad8e92093742c1fb4a2f75da4a6a9033836c0030c87876dc47430307817da0f84f99c7a2ac468904d687ac0035eb15fd825066f406b1f3413cc36d828eaaa31f36b3de0396c6067b1255db09ff57fc6f9beb3bccc84565757c80e90c715a88a51f9289b9b977c89d041c86b3c05e75d199fae16acc1a25253bde2538065ddc11d0b5ce5a76568207d2f568c688d0d4ac071cb78558b362371de2ad647dba16e62011bb0e41a54471e3b2d579f42db48efc13ff470136230cd4573f385fdfe8330904df71bd2531a338c317f89b5a14
"""

# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE
# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.
import kagglehub
kagglehub.login()

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

kmader_skin_cancer_mnist_ham10000_path = kagglehub.dataset_download('kmader/skin-cancer-mnist-ham10000')
chandrashekharkeeli_maxhealth_2017_path = kagglehub.dataset_download('chandrashekharkeeli/maxhealth-2017')
chandrashekharkeeli_maxmodel_path = kagglehub.dataset_download('chandrashekharkeeli/maxmodel')

print('Data source import complete.')

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import classification_report, confusion_matrix
import torchvision.transforms as T
import random

# =========================================================
# CONFIG & SEEDING
# =========================================================
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

set_seed()
device = "cuda" if torch.cuda.is_available() else "cpu"
DATA_PATH = "/kaggle/input/maxhealth-2017/candidate_dataset.npz"

# =========================================================
# IMPROVED PREPROCESSING (LUMA CONVERSION)
# =========================================================
def preprocess(x):
    if x.ndim == 4 and x.shape[-1] == 3:
        # Luma weighted average for high-fidelity grayscale
        x = np.dot(x[..., :3], [0.2989, 0.5870, 0.1140])
    return x.astype('float32') / 255.0

data = np.load(DATA_PATH)
x_train, y_train = preprocess(data["x_train"]), data["y_train"].squeeze()
x_val, y_val = preprocess(data["x_val"]), data["y_val"].squeeze()

# =========================================================
# NOISE-ROBUST LOSS (GENERALIZED CROSS ENTROPY)
# =========================================================
class GCELoss(nn.Module):
    def __init__(self, q=0.7, num_classes=7):
        super(GCELoss, self).__init__()
        self.q = q
        self.num_classes = num_classes

    def forward(self, logits, targets):
        probs = nn.functional.softmax(logits, dim=1)
        Yg = nn.functional.one_hot(targets, self.num_classes).float()
        loss = (1 - torch.pow(torch.sum(Yg * probs, dim=1), self.q)) / self.q
        return loss.mean()

# =========================================================
# RESIDUALLY-CONNECTED CNN
# =========================================================
class ResBlock(nn.Module):
    def __init__(self, in_channels):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, in_channels, 3, padding=1),
            nn.BatchNorm2d(in_channels),
            nn.ReLU(),
            nn.Conv2d(in_channels, in_channels, 3, padding=1),
            nn.BatchNorm2d(in_channels)
        )
    def forward(self, x):
        return nn.functional.relu(x + self.conv(x))

class AdvancedSkinCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.stem = nn.Sequential(
            nn.Conv2d(1, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU()
        )
        self.layer1 = ResBlock(64)
        self.layer2 = ResBlock(64)
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Dropout(0.4),
            nn.Linear(64, 7)
        )

    def forward(self, x):
        x = self.stem(x)
        x = self.layer1(x)
        x = nn.functional.max_pool2d(x, 2)
        x = self.layer2(x)
        return self.classifier(self.pool(x))

# =========================================================
# DATA LOADER SETUP
# =========================================================
class SkinDataset(Dataset):
    def __init__(self, x, y, augment=False):
        self.x, self.y = x, y
        self.transform = T.Compose([
            T.RandomHorizontalFlip(),
            T.RandomRotation(15),
            T.ColorJitter(brightness=0.1)
        ]) if augment else None

    def __len__(self): return len(self.y)

    def __getitem__(self, idx):
        img = torch.tensor(self.x[idx], dtype=torch.float32).unsqueeze(0)
        if self.transform: img = self.transform(img)
        return img, torch.tensor(self.y[idx], dtype=torch.long)

train_loader = DataLoader(SkinDataset(x_train, y_train, True), batch_size=64, shuffle=True)
val_loader = DataLoader(SkinDataset(x_val, y_val, False), batch_size=64)

# =========================================================
# TRAINING WITH COSINE ANNEALING
# =========================================================
model = AdvancedSkinCNN().to(device)
criterion = GCELoss(q=0.7)
optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)

best_acc = 0
for epoch in range(20):
    model.train()
    for x, y in train_loader:
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        loss = criterion(model(x), y)
        loss.backward()
        optimizer.step()

    scheduler.step()
    model.eval()
    preds, targets = [], []
    with torch.no_grad():
        for x, y in val_loader:
            out = model(x.to(device))
            preds.extend(out.argmax(1).cpu().numpy())
            targets.extend(y.numpy())

    acc = (np.array(preds) == np.array(targets)).mean()
    if acc > best_acc:
        best_acc = acc
        torch.save(model.state_dict(), "robust_model.pth")
    print(f"Epoch {epoch+1} | Val Acc: {acc:.4f}")

# =========================================================
# LIVE INFERENCE WITH CLASS-WISE ANALYSIS
# =========================================================
def run_live_inference(model_path, npz_path):
    model = AdvancedSkinCNN().to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()

    test_data = np.load(npz_path)
    x = preprocess(test_data["x_val"])
    y = test_data["y_val"].squeeze()

    x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(1).to(device)
    with torch.no_grad():
        outputs = model(x_tensor)
        preds = torch.argmax(outputs, 1).cpu().numpy()

    print("\n--- PERFORMANCE REPORT ---")
    print(classification_report(y, preds))

    return (preds == y).mean()

run_live_inference("robust_model.pth", DATA_PATH)

# =========================================================
# EVALUATION OF MODEL ON HAM10000
# =========================================================

import os
import numpy as np
import pandas as pd
from PIL import Image
from collections import Counter

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# -------------------------
# Device
# -------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# -------------------------
# Paths
# -------------------------
HAM_PATH = "/kaggle/input/skin-cancer-mnist-ham10000"
MODEL_PATH = "/kaggle/input/maxmodel/robust_model.pth"

CSV_PATH = os.path.join(HAM_PATH, "HAM10000_metadata.csv")
IMG_DIR_1 = os.path.join(HAM_PATH, "HAM10000_images_part_1")
IMG_DIR_2 = os.path.join(HAM_PATH, "HAM10000_images_part_2")

# -------------------------
# Load metadata
# -------------------------
df = pd.read_csv(CSV_PATH)

label_map = {
    "nv": 0,   # benign
    "mel": 1,  # malignant
    "bkl": 2,  # benign
    "bcc": 3,  # malignant
    "akiec": 4,# malignant
    "vasc": 5, # benign
    "df": 6    # benign
}

df = df[df["dx"].isin(label_map)].reset_index(drop=True)
df["label"] = df["dx"].map(label_map)

print("Total HAM10000 samples:", len(df))

# -------------------------
# Dataset
# -------------------------
class HAM10000Dataset(Dataset):
    def __init__(self, df):
        self.df = df

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_name = row["image_id"] + ".jpg"

        img_path = os.path.join(IMG_DIR_1, img_name)
        if not os.path.exists(img_path):
            img_path = os.path.join(IMG_DIR_2, img_name)

        img = Image.open(img_path).convert("RGB")
        img = img.resize((28, 28), Image.BILINEAR)

        # Luma grayscale
        img = np.dot(np.array(img), [0.2989, 0.5870, 0.1140])
        img = img.astype(np.float32) / 255.0
        img = np.expand_dims(img, axis=0)

        return torch.tensor(img), torch.tensor(row["label"]).long()

loader = DataLoader(
    HAM10000Dataset(df),
    batch_size=64,
    shuffle=False,
    num_workers=2,
    pin_memory=True
)

# -------------------------
# MODEL (MATCHES TRAINING)
# -------------------------
class ResBlock(nn.Module):
    def __init__(self, in_channels):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, in_channels, 3, padding=1),
            nn.BatchNorm2d(in_channels),
            nn.ReLU(),
            nn.Conv2d(in_channels, in_channels, 3, padding=1),
            nn.BatchNorm2d(in_channels)
        )

    def forward(self, x):
        return F.relu(x + self.conv(x))


class AdvancedSkinCNN(nn.Module):
    def __init__(self, num_classes=7):
        super().__init__()
        self.stem = nn.Sequential(
            nn.Conv2d(1, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU()
        )
        self.layer1 = ResBlock(64)
        self.layer2 = ResBlock(64)
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Dropout(0.4),
            nn.Linear(64, num_classes)
        )

    def forward(self, x):
        x = self.stem(x)
        x = self.layer1(x)
        x = F.max_pool2d(x, 2)
        x = self.layer2(x)
        x = self.pool(x)
        return self.classifier(x)

# -------------------------
# Load model safely
# -------------------------
checkpoint = torch.load(MODEL_PATH, map_location=device)
model = AdvancedSkinCNN().to(device)

if isinstance(checkpoint, dict) and "model_state_dict" in checkpoint:
    model.load_state_dict(checkpoint["model_state_dict"])
else:
    model.load_state_dict(checkpoint)

model.eval()
print("Model loaded successfully")

# -------------------------
# Inference
# -------------------------
all_preds, all_targets = [], []

with torch.no_grad():
    for imgs, labels in loader:
        imgs = imgs.to(device, non_blocking=True)
        outputs = model(imgs)
        preds = outputs.argmax(1).cpu().numpy()
        all_preds.extend(preds)
        all_targets.extend(labels.numpy())

# -------------------------
#  Prediction distribution
# -------------------------
print("\nPrediction Distribution:")
counts = Counter(all_preds)
total = sum(counts.values())
for cls in sorted(counts):
    print(f"Class {cls}: {counts[cls]/total:.2%}")

# -------------------------
#  Binary Benign vs Malignant
# -------------------------
benign = {0, 2, 5, 6}
malignant = {1, 3, 4}

binary_preds = [0 if p in benign else 1 for p in all_preds]
binary_targets = [0 if t in benign else 1 for t in all_targets]

binary_acc = accuracy_score(binary_targets, binary_preds)
print("\nBinary (Benign vs Malignant) Accuracy:", binary_acc)

print("\nBinary Confusion Matrix:")
print(confusion_matrix(binary_targets, binary_preds))

# -------------------------
#  7-class report (informational only)
# -------------------------
print("\nNOTE: 7-class report shown for completeness only (labels not aligned)")
print(classification_report(all_targets, all_preds, zero_division=0))
